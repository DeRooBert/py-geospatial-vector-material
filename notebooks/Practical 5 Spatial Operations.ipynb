{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 5: Spatial operations\n",
    "\n",
    "So far, the practicals have been introducing you to some of the key concepts of spatial data and some of the basic steps of properly handling things like CRS and measuring distance. This practical will start to shift more to providing you with a set of \"tools\" and when you might want to use them for analyses. This practical will cover topics in spatial operations that will involve geometric manipulations as well as (and in combination with) non-spatial data operations. \n",
    "\n",
    "Rather than dealing with relatively simple datasets as in the earlier practicals, this practical will also introduce a set of real-world datasets that you will be working with for the remainder of the workshop. This will give you some practice with a real workflow of loading, cleaning, joining up datasets. \n",
    "\n",
    "The objectives of this lesson are to:\n",
    "* understand different overlay operations and spatial relationships\n",
    "* carry out gemetric manipulations such as creating buffers, centroids, intersections\n",
    "* be able to join, select, aggregate, and dissolve GeoDataFrames\n",
    "* start creating more sophisticated maps and plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the package\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Southampton datasets\n",
    "\n",
    "I have assembled a few interesting datasets for Southampton (we won't use all in this practical). The data are located in the `/data` directory of the workshop materials folder. These files inclulde:\n",
    "* locations of fast food restaurants, convenience stores, and supermarkets\n",
    "* an [index of local deprivation](https://www.gov.uk/government/statistics/english-indices-of-deprivation-2019)\n",
    "* census boundaries and data on recent population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "Let's start by loading a dataset of census \"Output Areas\" (OAs). The OA is the smallest unit of population geography for the census in the UK. I've already created a subset of the national dataset. This will define our Southampton study area.\n",
    "\n",
    "In this practical we're going to look at the number of local supermarkets and the distance people have to travel to a supermarket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load output areas\n",
    "oa = gpd.read_file('../data/soton_OA_2011.gpkg')\n",
    "\n",
    "oa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll use data on local supermarkets. These data come from [OpenStreetMap](https://www.openstreetmap.org) and I've converted the GeoJSON files to GeoPackages. The data suffer from some errors, omissions, and gaps in information common with *volunteered geographic information*. \n",
    "\n",
    "For instance, these data come in two different representations: some stores are points and others are polygons. We will need to convert and combine these files before continuing with the analyses\n",
    "\n",
    "As a side note, a good tool in Python for extract OSM data is [OSMnx](https://github.com/gboeing/osmnx)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load supermarket points\n",
    "smkt_pts = gpd.read_file('../data/supermarket_pts.gpkg')\n",
    "\n",
    "smkt_pts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smkt_pts.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load supermarket polygons\n",
    "smkt_ply = gpd.read_file('../data/supermarket_poly.gpkg')\n",
    "\n",
    "smkt_ply.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smkt_ply.plot()  # note: the polygons are just really small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smkt_ply.geometry[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistent projections\n",
    "\n",
    "As we have seen in several practicals now, we need to consider the Coordinate Reference System when we're working with different datasets. Before we can combine the files, let's make sure the supermarket data align with the OA census data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRS of output areas\n",
    "oa.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRS of supermarkets\n",
    "print(smkt_pts.crs)\n",
    "print(smkt_ply.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of the OSM files of supermarkets are in WGS84 (EPSG:4326). We are going to project these to OSGB 1936. That projected coordinate system will help us make more accurate distance calculations in later steps of this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project supermarkets\n",
    "smkt_pts_prj = smkt_pts.to_crs(oa.crs)\n",
    "smkt_ply_prj = smkt_ply.to_crs(oa.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are using the same CRS, we can easily plot the data on the same map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# plot the outlines of the output areas\n",
    "oa.plot(ax=ax, color='white', edgecolor='black')\n",
    "\n",
    "# add just the supermarket points\n",
    "smkt_pts_prj.plot(ax=ax, marker='o', color='red', markersize=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice in the plot above that the points are well outside of just Southampton (including Portsmouth!). I downloaded a larger area. We'll next clip the data down to just our study area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Soton data\n",
    "\n",
    "An easy way to extract spatial data for only a specific region of interest is to use the `clip` function in `GeoPandas`. Clip will modify the geometry of the object being \"clipped\". In this instance, we will want to clip the supermarkets by the geometry of the OAs to create a new supermarket dataset for only Southampton locations.\n",
    "\n",
    "For more information on this operation, see here: [https://geopandas.org/gallery/plot_clip.html](https://geopandas.org/gallery/plot_clip.html)\n",
    "\n",
    "But we need need to consider some of the effects of reducing our study area. Restricting our supermarkets to only those within the OA boundaries could create what are known as **edge effects** in our study. The OAs on the edge of the study area may appear to have higher distances to supermarkets because we've limited our options to only those inside the city area. We'll avoid (some) of the edge effects of clipping, by first creating a spatial buffer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buffering and clipping\n",
    "\n",
    "Buffering and clipping spatial data are two of the most fundamental operations. These derive from `shapely` and you can find more information here: [https://geopandas.org/geometric_manipulations.html](https://geopandas.org/geometric_manipulations.html).\n",
    "\n",
    "Let's start with just a simple buffer example to illustrate the idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "from descartes import PolygonPatch\n",
    "\n",
    "# create a geometry with a simple location\n",
    "p = Polygon([(2, 0), (3, 0), (3, 1), (2, 1)])\n",
    "\n",
    "# buffer to creat a rounded rectangle\n",
    "p.buffer(3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Southampton, we're going to use the OAs and buffer them by 1000 meters. But there are multiple polygons in that GeoDataFrame. Let's first simplify it by using another geometric operation - the **union** of the geometries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all the OA shapes - we'll do this and create a new `GeoDataFrame`\n",
    "# buffer by 1km (note: units defined by the CRS)\n",
    "oa_buffer = gpd.GeoDataFrame({\n",
    "                              'id':[1],\n",
    "                              'geometry': oa.unary_union.buffer(1000) # combining these operations into 1 step\n",
    "                             }, crs=\"EPSG:27700\") # remember to define the CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "oa_buffer.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having completed these preparations, now we can clip the supermarkets and move on to combining them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clipping step\n",
    "smkt_pts_soton = gpd.clip(smkt_pts_prj, oa_buffer)\n",
    "smkt_ply_soton = gpd.clip(smkt_ply_prj, oa_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat the plot to see the results of the clipping\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# plot the outlines of the output areas\n",
    "oa.plot(ax=ax, color='white', edgecolor='black')\n",
    "\n",
    "# add just the supermarket points\n",
    "smkt_pts_soton.plot(ax=ax, marker='o', color='red', markersize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could have subset the supermarkets by their city attribute (`== 'Southampton'`), but here we're showing you a geographical approach. You can't subset the data and include a buffer to avoid edge effects using only the attributes in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and combining files\n",
    "\n",
    "The next step in our pre-processing workflow is to combine the supermarket points and polygons into a single file. We want to: 1) convert the polygons to a point represenation, and then 2) combine the two point `GeoDataFrames` into a single object that we can work with.\n",
    "\n",
    "To convert from polygons to points, we will use each polygon's **centroid** location. The centroid is the geometric center of the shape. If our polygons have strange and complicated shapes, holes or have multipolygon pieces, we can still calculate a centroid, but sometimes it won't be contained by the original polygon. Just be aware of this fact. It won't affect our analyses.\n",
    "\n",
    "In `GeoPandas` the centroid is exposed as a basic method for all data frames with `.centroid`. This returns a `GeoSeries` which we can use to assign to the geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create centroids of supermarkets\n",
    "# assign them to the geometry (overwrite the polygons!)\n",
    "smkt_ply_soton.geometry = smkt_ply_soton.centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all points now\n",
    "smkt_ply_soton.geometry.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have two point-geometry files of supermarket locations, we want to combine them into a single object. We will do this using an `append` command that comes from `Pandas`. This is a simple command to execute because we've already done the careful preprocessing to make sure the CRS are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a unified supermarket dataset\n",
    "smkts = smkt_pts_soton.append(smkt_ply_soton)\n",
    "\n",
    "smkts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data size\n",
    "[smkt_pts_soton.shape, smkt_ply_soton.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "smkts.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "smkts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate our basic data plot with the new dataset\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# plot the outlines of the output areas\n",
    "oa.plot(ax=ax, color='white', edgecolor='black')\n",
    "\n",
    "# add just the supermarket points\n",
    "smkts.plot(ax=ax, marker='o', color='red', markersize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis using Point-in-Polygon\n",
    "\n",
    "Everything we've done thus far has been data preparation and cleaning. We can finally start to analyse our data!\n",
    "\n",
    "Our first question is relatively simple to phrase: *how many supermarkets are there in an area?*\n",
    "\n",
    "For this analysis we will first use the OA boundaries. Then we will look at how we might summarise the results at different geographic scales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a 'spatial join'\n",
    "\n",
    "There are several ways we might answer this question, but we'll use this as an opportunity to look at the *spatial join* in more detail. A spatial join is a way to merge information based on geometric overlays. You can assign or combine information based on what is contained or intersects another geographic shape. A *spatial* join is similar, conceptually, to a *non*-spatial join that you may be familiar with from `pandas` or other SQL-type operations.\n",
    "\n",
    "In `GeoPandas` these operations are carried out using `.sjoin`. The documentation ([here](https://geopandas.org/mergingdata.html?highlight=spatial%20join#sjoin-arguments)) explains that it takes two important arguments:\n",
    "* `op`: specifying the geometry operation as intersects, within, contains\n",
    "* `how`: defining the join as left, right, or inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a spatial join of points within polygons\n",
    "# store in a new GeoDataFrame\n",
    "oa_sj = gpd.sjoin(oa, \n",
    "                  smkts, \n",
    "                  how='inner' \n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa_sj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa_sj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how there are now fewer records in the spatially joined data frame. That's because we used an 'inner' join. Any polygon that doesn't have a point is dropped. If we had used a 'left' join then the polygons would have been duiplicated when the contain more than one point and polygons with zero points would have been kept.\n",
    "\n",
    "We can use some `pandas` techniques to aggregate and count the records based on their unique OA code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of points per unique OA (identified by the attribute [code])\n",
    "smkt_count = oa_sj.groupby('code').code.count()\n",
    "\n",
    "smkt_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a non-spatial join\n",
    "\n",
    "To add the the summarised counts of supermarkets back into our original `GeoDataFrame`, we will use a type of non-spatial join operation to *merge* the data. In this operation, notice that we're merging non-spatial data with spatial data, but the `GeoDataFrame` is still recognised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join counts to the OAs and store in a new object\n",
    "# note that we use 'right_index' because we don't have a separate attribute column, just the index\n",
    "oa_smkt_count = oa.merge(smkt_count.to_frame('smkt_count'), # create a column label\n",
    "                         how='left',  # keep all the OA records\n",
    "                         left_on='code',\n",
    "                         right_index=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the result. Most NAs where there were no points.\n",
    "oa_smkt_count[['code','smkt_count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing the results\n",
    "\n",
    "We can create a simple **choropleth** map by specifying the column of data in the `.plot()` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# create a plot of the count of points by OA\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "\n",
    "# make the legend line up with the size of the plot\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "\n",
    "oa_smkt_count.plot(column='smkt_count', \n",
    "                   ax=ax, \n",
    "                   legend=True, \n",
    "                   cax=cax,\n",
    "                   missing_kwds={'color': 'lightgrey'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dissolving to aggregate data\n",
    "\n",
    "The output areas are really too small for this analysis to be useful. Most of the results show that zero supermarkets in the OA. However, census data in the UK are built on a hierarchy of geometries. Ouput areas combine into larger units called \"Lower Super Output Areas\" or LSOAs. \n",
    "\n",
    "We're going to create a LSOAs dataset from our OAs by extracting the LSOA identifier, and then *dissolving* the OAs to create a new, aggregated dataset. This gives us a chance to practice a few other data processing and spatial operations.\n",
    "\n",
    "Dissolving is a very useful operation because it allows you summarise both spatial and non-spatial information. It's like performing a union on the geometries while also performing an aggergate function on the attribute columns. This is described in more detail [here](https://geopandas.org/aggregation_with_dissolve.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember what format we have\n",
    "oa_smkt_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new identifier column of LSOA codes from the OA codes\n",
    "# use `pandas` functions to slice the string and create a new column\n",
    "oa_smkt_count['lsoa'] = oa_smkt_count['label'].str.slice(start=18, stop=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa_smkt_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this new identifier `[lsoa]` we can use it create a new set of geometries. In the same step, we can aggregate our variable of interest (the count of supermarkets) and create a new data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `dissolve` the OA data to create LSOA boundaries\n",
    "# sum the count of supermarkets within the new areas\n",
    "lsoa_smkt_count = oa_smkt_count[['lsoa','smkt_count','geometry']].dissolve(by='lsoa', aggfunc='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lsoa_smkt_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that by dissolving we're left with values of 0.0 instead of `Nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsoa_smkt_count.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing the results (2)\n",
    "\n",
    "Let's create another plot of the LSOA results. We'll continue to use the defaul colour schemes for now, but we'll soon look at how to improve on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a plot of the count of points by LSOA\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "\n",
    "# make the legend line up with the size of the plot\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "\n",
    "lsoa_smkt_count.plot(column='smkt_count', \n",
    "                     ax=ax, \n",
    "                     legend=True, \n",
    "                     cax=cax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now answered our first question - we have both a map and a table of the number of supermarkets in each area of Southampton. It seems like the stores are very clustered. Some places have three or four markets, while most others have none.\n",
    "\n",
    "To answer this question we've done spatial and non-spatial joins, aggegated data, and dissolved geographic data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance calculations (returned)\n",
    "\n",
    "For our next analysis, let's return to our last practical and revisit distance calculations. \n",
    "\n",
    "In this next section we aim to answer: *how far do people have to travel to reach a supermarket?*\n",
    "\n",
    "Luckily our data are already cleaned, merged, and ready for analysis. We need to think a bit more about how we define \"distance\" given our data. We have polygon representations of census areas. That's typically the kind of data you'll work with, but it's not ideal. It doesn't give you very high *resolution* of where people exactly live. Also, when we measure distances between polygons, the default behaviour is to measure from the closest border point. An oddly shaped polygon could give you strange results in that case.\n",
    "\n",
    "So we are going to have to approximate the average travel distance for all households within a census area.\n",
    "\n",
    "Note, for this analysis, let's continue to use LSOAs rather than the smaller OAs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating centroids\n",
    "\n",
    "We've already seen one potential solution for addressing the issue of measuring distances and polygon edges - we can change the geometry representation of LSOAs from a polygon to its centroid point. This is a common approximation when working with (relatively) small geographic areas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert lsoa to centroid points\n",
    "# store this as a separate `GeoSeries`. We don't need a full DataFrame\n",
    "lsoa_pts = lsoa_smkt_count.centroid\n",
    "\n",
    "lsoa_pts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step simplifies our analysis problem considerably. Now we to have measure the distance between sets of points, which we did in the previous practical!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest supermarket\n",
    "\n",
    "For each LSOA area, find the distance to the nearest supermarket. Remember that our CRS is already projected (we're using EPSG 27700), so it's appropriate to use Euclidean distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the distance from LSOA centroids to supermarkets\n",
    "# use a unary union to combine supermarket locations and find the nearest distance\n",
    "lsoa_smkt_count['smkt_dist'] = lsoa_pts.distance(smkts.unary_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lsoa_smkt_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We added our results our calculation back to the original LSOA polygon dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a plot of the distance to supermarkets by LSOA\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "\n",
    "# make the legend line up with the size of the plot\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "\n",
    "lsoa_smkt_count.plot(column='smkt_dist', \n",
    "                     ax=ax, \n",
    "                     legend=True, \n",
    "                     cax=cax)\n",
    "\n",
    "# add the locations of supermarkets\n",
    "smkts.plot(ax=ax, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save your work\n",
    "\n",
    "We'll return to this LSOA dataset in later exercises, so go ahead and save this file. Remember that you may need to update the file paths in the code shown below, depending on how you're running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out GeoDataFrame to GeoPackage file\n",
    "lsoa_smkt_count.to_file('../data/soton_lsoa_distance.gpkg', driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choropleth maps\n",
    "\n",
    "It's time to start improving our maps. We've been using the default parameters and they've been working OK, but the distance calculations give us an opportunity to explore some other mapping techniques, particularly how we categorise data in the legend.\n",
    "\n",
    "Don't worry this is just a warm-up, the next practicals will be all about geovisualisations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colour maps\n",
    "\n",
    "As mentioned before, the `plot()` method in `GeoPandas` relies on `matplotlib`. This allows us to make use of many of those features and extensions. This includes [colourmaps](https://matplotlib.org/tutorials/colors/colormaps.html).)\n",
    "\n",
    "Let's change our map to use a colour gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "\n",
    "# make the legend line up with the size of the plot\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "\n",
    "lsoa_smkt_count.plot(column='smkt_dist', \n",
    "                     ax=ax, \n",
    "                     cmap='RdPu',  # THIS is the new part\n",
    "                     legend=True, \n",
    "                     cax=cax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data bins\n",
    "\n",
    "Rather than letting `.plot()` decide how to assign colours to data and treating it as continuous, let's take a little control and plot the LSOA by quintile of distance values.\n",
    "\n",
    "This step will start using `mapclassify` and the documentation and examples can be found on the website: [https://pysal.org/mapclassify/index.html](https://pysal.org/mapclassify/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsoa_smkt_count.plot(column='smkt_dist', \n",
    "                     cmap='RdPu', \n",
    "                     scheme='Quantiles', # THIS is new\n",
    "                     k=5, # THIS define the number of groups, 5=quintiles\n",
    "                     legend=True,\n",
    "                     legend_kwds={'title':\"Supermarket Dist (m)\"}, # add a name\n",
    "                     figsize=(15,10) # adjust the size so the legend doesn't overlap\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finished! Well done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
